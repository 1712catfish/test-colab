{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPw/i28fE/Yu5VHvGUAYfQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da4c85e3fd044a23aea8050a6b5f73a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0478f08e93d473cbb01982e754ce697",
              "IPY_MODEL_6274c46c3bb94d7994d98c979f8de987",
              "IPY_MODEL_8163317d4cd0422f90816e45770a0e34"
            ],
            "layout": "IPY_MODEL_5988c3f7d3ba41379579b652916c765f"
          }
        },
        "a0478f08e93d473cbb01982e754ce697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac46ed4f9244a79a7aef457514f3a04",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d3ab9ae5d14e3385c4ccd630a5ef00",
            "value": "config.json: 100%"
          }
        },
        "6274c46c3bb94d7994d98c979f8de987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ada5b2571333461f8b69e018873af7f8",
            "max": 557,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_def8a19579a4414ba613f042d68f6b36",
            "value": 557
          }
        },
        "8163317d4cd0422f90816e45770a0e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d166d1fda42341ec841be79acef5a901",
            "placeholder": "​",
            "style": "IPY_MODEL_270ebe2a76ec40b9a42c3c99c57f2e0d",
            "value": " 557/557 [00:00&lt;00:00, 12.7kB/s]"
          }
        },
        "5988c3f7d3ba41379579b652916c765f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac46ed4f9244a79a7aef457514f3a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d3ab9ae5d14e3385c4ccd630a5ef00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ada5b2571333461f8b69e018873af7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "def8a19579a4414ba613f042d68f6b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d166d1fda42341ec841be79acef5a901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "270ebe2a76ec40b9a42c3c99c57f2e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "897be82b2d274a1c96c9575e36cdc923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1adefcee9a2f43b5b5bd18cb0bdce543",
              "IPY_MODEL_9da1deddf9b64b5b8fb0b6306ff9725a",
              "IPY_MODEL_a1a2198d6f59412ca4ed5e6cdf12c198"
            ],
            "layout": "IPY_MODEL_de71b5f040ce48f9ad676722a54d6ac0"
          }
        },
        "1adefcee9a2f43b5b5bd18cb0bdce543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27360e065a58450f93f4ab431245f69e",
            "placeholder": "​",
            "style": "IPY_MODEL_8f06d66ef58742b4aefb6166c527093f",
            "value": "vocab.txt: 100%"
          }
        },
        "9da1deddf9b64b5b8fb0b6306ff9725a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4b93fded444352860dffb009bf68d3",
            "max": 895321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ab67fdef5204cf4b5f2344a94f7796e",
            "value": 895321
          }
        },
        "a1a2198d6f59412ca4ed5e6cdf12c198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5879f38b6d345d5a2f5e8e55b08820b",
            "placeholder": "​",
            "style": "IPY_MODEL_003664cd03ce4bdfa7dff22fbcc21f08",
            "value": " 895k/895k [00:00&lt;00:00, 5.22MB/s]"
          }
        },
        "de71b5f040ce48f9ad676722a54d6ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27360e065a58450f93f4ab431245f69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f06d66ef58742b4aefb6166c527093f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d4b93fded444352860dffb009bf68d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab67fdef5204cf4b5f2344a94f7796e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5879f38b6d345d5a2f5e8e55b08820b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "003664cd03ce4bdfa7dff22fbcc21f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ba0c34c1bb1490da1e27c4f13d74c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e28bd5ff09c406f9560bd586af5174c",
              "IPY_MODEL_ca4debb4216e49169801245f83c7ff8a",
              "IPY_MODEL_bbae2e88ffb04949b455b84758149b9f"
            ],
            "layout": "IPY_MODEL_1e99660664e1456497bc5ef0755e76c2"
          }
        },
        "3e28bd5ff09c406f9560bd586af5174c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876989b2f7f84f55a4d5a5aa50fd81af",
            "placeholder": "​",
            "style": "IPY_MODEL_d8fb617a7eea4f03bca72e85156f2412",
            "value": "bpe.codes: 100%"
          }
        },
        "ca4debb4216e49169801245f83c7ff8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7eda2ab0074b4dba3a9a8ea8323e9a",
            "max": 1135173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29636ee9dd3d456b9f62d1d4dea1daf5",
            "value": 1135173
          }
        },
        "bbae2e88ffb04949b455b84758149b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20801dcbc4b54cc2874d733c00b00654",
            "placeholder": "​",
            "style": "IPY_MODEL_af937dbde4744bd89237d2023d50cb03",
            "value": " 1.14M/1.14M [00:00&lt;00:00, 16.7MB/s]"
          }
        },
        "1e99660664e1456497bc5ef0755e76c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876989b2f7f84f55a4d5a5aa50fd81af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8fb617a7eea4f03bca72e85156f2412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7eda2ab0074b4dba3a9a8ea8323e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29636ee9dd3d456b9f62d1d4dea1daf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20801dcbc4b54cc2874d733c00b00654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af937dbde4744bd89237d2023d50cb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "387e11b94cb344598848ecf1e5b8fbb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e281f98667df404eb348f5b9963c8ecd",
              "IPY_MODEL_eb18e47c675e4a36b4c252799072fdca",
              "IPY_MODEL_531b38ec83074a9bab73ae3727b861b9"
            ],
            "layout": "IPY_MODEL_737595e03ca3400f8723c6c5f4503e4d"
          }
        },
        "e281f98667df404eb348f5b9963c8ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_623e530e0a66495186bb22d918cb1c77",
            "placeholder": "​",
            "style": "IPY_MODEL_c8c0e937c98f4451b0e8eef84361e67f",
            "value": "tokenizer.json: 100%"
          }
        },
        "eb18e47c675e4a36b4c252799072fdca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c82e14cb3345149d0ef87927713428",
            "max": 3132320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_721c735d40874f73bb183875e1953fce",
            "value": 3132320
          }
        },
        "531b38ec83074a9bab73ae3727b861b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22bd04b7faa74460811212306ee554ae",
            "placeholder": "​",
            "style": "IPY_MODEL_08325274087844278b2333951ab7882b",
            "value": " 3.13M/3.13M [00:00&lt;00:00, 20.3MB/s]"
          }
        },
        "737595e03ca3400f8723c6c5f4503e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623e530e0a66495186bb22d918cb1c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c0e937c98f4451b0e8eef84361e67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45c82e14cb3345149d0ef87927713428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "721c735d40874f73bb183875e1953fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22bd04b7faa74460811212306ee554ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08325274087844278b2333951ab7882b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1712catfish/test-colab/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LMiiKKnZMJJS",
        "outputId": "7f05f68a-bc5c-4efd-ac7c-dc07b6e08719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1q3myiaORcL3fbeks8ExZZcqefFtHthPD\n",
            "To: /content/vlsp_sentiment_train.csv\n",
            "100%|██████████| 858k/858k [00:00<00:00, 62.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jofip_UbAXzzJwrqacVTJ7183mmpBQXe\n",
            "To: /content/vlsp_sentiment_test.csv\n",
            "100%|██████████| 159k/159k [00:00<00:00, 90.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.2.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.9 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n",
            "Collecting textaugment\n",
            "  Downloading textaugment-2.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textaugment) (3.8.1)\n",
            "Requirement already satisfied: gensim>=4.0 in /usr/local/lib/python3.10/dist-packages (from textaugment) (4.3.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from textaugment) (0.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from textaugment) (1.23.5)\n",
            "Collecting googletrans>=2 (from textaugment)\n",
            "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0->textaugment) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0->textaugment) (6.4.0)\n",
            "Collecting httpx==0.13.3 (from googletrans>=2->textaugment)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans>=2->textaugment) (2023.7.22)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans>=2->textaugment) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans>=2->textaugment)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->textaugment) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textaugment) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->textaugment) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->textaugment) (4.66.1)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15717 sha256=7c12a769093606f40cbb521666537a06f119d38b465bf923d70a644d9d2c8c12\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/81/ea/8b030407f8ebfc2f857814e086bb22ca2d4fea1a7be63652ab\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans, textaugment\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "Successfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0 textaugment-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "idna"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lion-pytorch\n",
            "  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from lion-pytorch) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->lion-pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->lion-pytorch) (1.3.0)\n",
            "Installing collected packages: lion-pytorch\n",
            "Successfully installed lion-pytorch-0.1.2\n",
            "Collecting py_vncorenlp\n",
            "  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius (from py_vncorenlp)\n",
            "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: py_vncorenlp\n",
            "  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4306 sha256=36b22d6dbc71d7d033f47390be84ad767d014bad76044af3d17ccb68cf78d057\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
            "Successfully built py_vncorenlp\n",
            "Installing collected packages: pyjnius, py_vncorenlp\n",
            "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1q3myiaORcL3fbeks8ExZZcqefFtHthPD'\n",
        "output = 'vlsp_sentiment_train.csv'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1jofip_UbAXzzJwrqacVTJ7183mmpBQXe'\n",
        "output = 'vlsp_sentiment_test.csv'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "!pip install pyvi\n",
        "!pip install textaugment\n",
        "!pip install lion-pytorch\n",
        "!pip install py_vncorenlp\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import digits\n",
        "from collections import Counter\n",
        "from pyvi import ViTokenizer\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import digits\n",
        "\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import gc\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import transformers\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "from sklearn import metrics\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import re\n",
        "from datasets import load_dataset, Audio\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "jqO3ia53Naug"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_vlsp_label(label, label_smoothing=0):\n",
        "    if label == -1:\n",
        "        return [1, 0, 0]\n",
        "    elif label == 0:\n",
        "        return [0, 1, 0]\n",
        "    else:\n",
        "        return [0, 0, 1]\n",
        "\n",
        "vlsp_train = pd.read_csv(\"vlsp_sentiment_train.csv\", sep='\\t')\n",
        "vlsp_train.columns =['Class', 'Data']\n",
        "vlsp_train = vlsp_train.sample(frac=1)\n",
        "vlsp_train = vlsp_train['Data'].values.tolist(), [prep_vlsp_label(x) for x in vlsp_train['Class'].values.tolist()]\n",
        "\n",
        "vlsp_test = pd.read_csv(\"vlsp_sentiment_test.csv\", sep='\\t')\n",
        "vlsp_test.columns =['Class', 'Data']\n",
        "vlsp_test = vlsp_test['Data'].values.tolist(), [prep_vlsp_label(x, label_smoothing=0) for x in vlsp_test['Class'].values.tolist()]"
      ],
      "metadata": {
        "id": "9Njh8y0rNbvo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 1234\n",
        "MAXLEN = 400\n",
        "sample_corpus = vlsp_train[0][:k]\n",
        "\n",
        "vocab_size = 7000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, lower=True, char_level=False)\n",
        "tokenizer.fit_on_texts(sample_corpus)\n",
        "\n",
        "data_train = vlsp_train\n",
        "data_train = shuffle(data_train[0], data_train[1])\n",
        "\n",
        "def tokenize(texts):\n",
        "    res = tokenizer.texts_to_sequences(texts)\n",
        "    res = pad_sequences(res, maxlen=MAXLEN)\n",
        "    return np.array(res)\n",
        "\n",
        "data_train = tokenize(data_train[0]), np.array(data_train[1])"
      ],
      "metadata": {
        "id": "ENqYvNJANiAR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = vlsp_test\n",
        "data_test = tokenize(data_test[0]), np.array(data_test[1])"
      ],
      "metadata": {
        "id": "KNHKHTZDN8GZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cnn"
      ],
      "metadata": {
        "id": "D7cenZZpUEBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.preprocessing import sequence as sq\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda, concatenate,Input,TimeDistributed,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "max_features = 21540#14300\n",
        "maxlen = 400\n",
        "batch_size = 10\n",
        "embedding_dims = 200\n",
        "nb_filter = 150\n",
        "filter_length = 3\n",
        "hidden_dims = 100\n",
        "nb_epoch = 14\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "input_layer = Input(shape=(maxlen,),dtype='int32', name='main_input')\n",
        "emb_layer = Embedding(max_features,\n",
        "                    embedding_dims,\n",
        "                    input_length=maxlen\n",
        "                    )(input_layer)\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 3:\n",
        "\n",
        "con3_layer = Conv1D(nb_filter,\n",
        "                    3,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con3_layer = Lambda(max_1d, output_shape=(nb_filter,))(con3_layer)\n",
        "\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 4:\n",
        "\n",
        "con4_layer = Conv1D(nb_filter,\n",
        "                    5,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con4_layer = Lambda(max_1d, output_shape=(nb_filter,))(con4_layer)\n",
        "\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 5:\n",
        "\n",
        "con5_layer = Conv1D(nb_filter,\n",
        "                    7,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con5_layer = Lambda(max_1d, output_shape=(nb_filter,))(con5_layer)\n",
        "\n",
        "\n",
        "cnn_layer = concatenate([pool_con3_layer, pool_con5_layer,pool_con4_layer ])\n",
        "\n",
        "\n",
        "#LSTM\n",
        "\n",
        "\n",
        "# x = Embedding(max_features, embedding_dims, input_length=maxlen)(input_layer)\n",
        "# lstm_layer = LSTM(128)(x)\n",
        "\n",
        "# cnn_lstm_layer = concatenate([lstm_layer, cnn_layer])\n",
        "\n",
        "cnn_lstm_layer = cnn_layer\n",
        "\n",
        "dense_layer = Dense(hidden_dims*2, activation='sigmoid')(cnn_lstm_layer)\n",
        "output_layer= Dropout(0.2)(dense_layer)\n",
        "output_layer = Dense(3, trainable=True,activation='softmax')(output_layer)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "adadelta = Adadelta(1.0, rho=0.95, epsilon=1e-06)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=\"adamax\",\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XCg5EtA_MWs9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn lstm 0.7\n",
        "# cnn lstm 0.68\n"
      ],
      "metadata": {
        "id": "tfDgNzI6SYc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(\n",
        "#     loss=tf.keras.losses.CategoricalCrossentropy(\n",
        "#         label_smoothing=0.0,\n",
        "#     ),\n",
        "#     optimizer=adam,\n",
        "#     metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')]\n",
        "# )\n",
        "\n",
        "model.fit(\n",
        "    *data_train,\n",
        "    epochs=10,\n",
        "    batch_size=10,\n",
        "    validation_data=data_test,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaxmxuGEMuU3",
        "outputId": "860dd892-66eb-4115-8aec-3dd26479166f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "510/510 [==============================] - 28s 50ms/step - loss: 1.0545 - accuracy: 0.4361 - val_loss: 0.9044 - val_accuracy: 0.5829\n",
            "Epoch 2/10\n",
            "510/510 [==============================] - 13s 25ms/step - loss: 0.7864 - accuracy: 0.6549 - val_loss: 0.7826 - val_accuracy: 0.6429\n",
            "Epoch 3/10\n",
            "510/510 [==============================] - 8s 16ms/step - loss: 0.5998 - accuracy: 0.7622 - val_loss: 0.7421 - val_accuracy: 0.6790\n",
            "Epoch 4/10\n",
            "510/510 [==============================] - 6s 12ms/step - loss: 0.4545 - accuracy: 0.8310 - val_loss: 0.7572 - val_accuracy: 0.6714\n",
            "Epoch 5/10\n",
            "510/510 [==============================] - 7s 13ms/step - loss: 0.3044 - accuracy: 0.9012 - val_loss: 0.7800 - val_accuracy: 0.6800\n",
            "Epoch 6/10\n",
            "510/510 [==============================] - 6s 12ms/step - loss: 0.1764 - accuracy: 0.9537 - val_loss: 0.8407 - val_accuracy: 0.6895\n",
            "Epoch 7/10\n",
            "510/510 [==============================] - 5s 10ms/step - loss: 0.0825 - accuracy: 0.9880 - val_loss: 0.9112 - val_accuracy: 0.6857\n",
            "Epoch 8/10\n",
            "510/510 [==============================] - 6s 13ms/step - loss: 0.0426 - accuracy: 0.9951 - val_loss: 1.0024 - val_accuracy: 0.6829\n",
            "Epoch 9/10\n",
            "510/510 [==============================] - 5s 10ms/step - loss: 0.0202 - accuracy: 0.9988 - val_loss: 1.0777 - val_accuracy: 0.6857\n",
            "Epoch 10/10\n",
            "510/510 [==============================] - 6s 12ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 1.1572 - val_accuracy: 0.6867\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f88d2a9d450>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "single lstm"
      ],
      "metadata": {
        "id": "gPibfxlSUAnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.preprocessing import sequence as sq\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda, concatenate,Input,TimeDistributed,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "max_features = 21540#14300\n",
        "maxlen = 400\n",
        "batch_size = 10\n",
        "embedding_dims = 200\n",
        "nb_filter = 150\n",
        "filter_length = 3\n",
        "hidden_dims = 100\n",
        "nb_epoch = 14\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "input_layer = Input(shape=(maxlen,),dtype='int32', name='main_input')\n",
        "emb_layer = Embedding(max_features,\n",
        "                    embedding_dims,\n",
        "                    input_length=maxlen\n",
        "                    )(input_layer)\n",
        "# def max_1d(X):\n",
        "#     return K.max(X, axis=1)\n",
        "\n",
        "# # we add a Convolution1D, which will learn nb_filter\n",
        "# # word group filters of size 3:\n",
        "\n",
        "# con3_layer = Conv1D(nb_filter,\n",
        "#                     3,\n",
        "#                     padding='valid',\n",
        "#                     activation='relu',)(emb_layer)\n",
        "\n",
        "# pool_con3_layer = Lambda(max_1d, output_shape=(nb_filter,))(con3_layer)\n",
        "\n",
        "\n",
        "# # we add a Convolution1D, which will learn nb_filter\n",
        "# # word group filters of size 4:\n",
        "\n",
        "# con4_layer = Conv1D(nb_filter,\n",
        "#                     5,\n",
        "#                     padding='valid',\n",
        "#                     activation='relu',)(emb_layer)\n",
        "\n",
        "# pool_con4_layer = Lambda(max_1d, output_shape=(nb_filter,))(con4_layer)\n",
        "\n",
        "\n",
        "# # we add a Convolution1D, which will learn nb_filter\n",
        "# # word group filters of size 5:\n",
        "\n",
        "# con5_layer = Conv1D(nb_filter,\n",
        "#                     7,\n",
        "#                     padding='valid',\n",
        "#                     activation='relu',)(emb_layer)\n",
        "\n",
        "# pool_con5_layer = Lambda(max_1d, output_shape=(nb_filter,))(con5_layer)\n",
        "\n",
        "\n",
        "# cnn_layer = concatenate([pool_con3_layer, pool_con5_layer,pool_con4_layer ])\n",
        "\n",
        "\n",
        "#LSTM\n",
        "\n",
        "x = Embedding(max_features, embedding_dims, input_length=maxlen)(input_layer)\n",
        "lstm_layer = LSTM(128)(x)\n",
        "\n",
        "# cnn_lstm_layer = concatenate([lstm_layer, cnn_layer])\n",
        "\n",
        "cnn_lstm_layer = lstm_layer\n",
        "\n",
        "dense_layer = Dense(hidden_dims*2, activation='sigmoid')(cnn_lstm_layer)\n",
        "output_layer= Dropout(0.2)(dense_layer)\n",
        "output_layer = Dense(3, trainable=True,activation='softmax')(output_layer)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "adadelta = Adadelta(1.0, rho=0.95, epsilon=1e-06)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=\"adamax\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    *data_train,\n",
        "    epochs=10,\n",
        "    batch_size=10,\n",
        "    validation_data=data_test,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvsDwngsS-_-",
        "outputId": "2492583a-ea0a-4127-f44a-c244e13111b7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "510/510 [==============================] - 34s 63ms/step - loss: 1.0859 - accuracy: 0.4075 - val_loss: 0.9409 - val_accuracy: 0.5352\n",
            "Epoch 2/10\n",
            "510/510 [==============================] - 17s 33ms/step - loss: 0.9045 - accuracy: 0.5700 - val_loss: 0.8836 - val_accuracy: 0.5886\n",
            "Epoch 3/10\n",
            "510/510 [==============================] - 14s 27ms/step - loss: 0.7789 - accuracy: 0.6657 - val_loss: 0.8037 - val_accuracy: 0.6486\n",
            "Epoch 4/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.6744 - accuracy: 0.7237 - val_loss: 0.7941 - val_accuracy: 0.6724\n",
            "Epoch 5/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.6047 - accuracy: 0.7633 - val_loss: 0.7812 - val_accuracy: 0.6695\n",
            "Epoch 6/10\n",
            "510/510 [==============================] - 12s 24ms/step - loss: 0.5454 - accuracy: 0.7873 - val_loss: 0.8314 - val_accuracy: 0.6781\n",
            "Epoch 7/10\n",
            "510/510 [==============================] - 18s 35ms/step - loss: 0.4977 - accuracy: 0.8122 - val_loss: 0.8497 - val_accuracy: 0.6629\n",
            "Epoch 8/10\n",
            "510/510 [==============================] - 16s 30ms/step - loss: 0.4463 - accuracy: 0.8351 - val_loss: 0.8874 - val_accuracy: 0.6695\n",
            "Epoch 9/10\n",
            "510/510 [==============================] - 14s 27ms/step - loss: 0.4024 - accuracy: 0.8525 - val_loss: 0.9723 - val_accuracy: 0.6695\n",
            "Epoch 10/10\n",
            "510/510 [==============================] - 15s 30ms/step - loss: 0.3776 - accuracy: 0.8633 - val_loss: 0.9562 - val_accuracy: 0.6562\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8888033760>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "many lstm"
      ],
      "metadata": {
        "id": "h-2H_ph7WK2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.preprocessing import sequence as sq\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda, concatenate,Input,TimeDistributed,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "max_features = 21540#14300\n",
        "maxlen = 400\n",
        "batch_size = 10\n",
        "embedding_dims = 200\n",
        "nb_filter = 150\n",
        "filter_length = 3\n",
        "hidden_dims = 100\n",
        "nb_epoch = 14\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "input_layer = Input(shape=(maxlen,),dtype='int32', name='main_input')\n",
        "emb_layer = Embedding(max_features,\n",
        "                    embedding_dims,\n",
        "                    input_length=maxlen\n",
        "                    )(input_layer)\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 3:\n",
        "\n",
        "con3_layer = Conv1D(nb_filter,\n",
        "                    3,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con3_layer = Lambda(max_1d, output_shape=(nb_filter,))(con3_layer)\n",
        "\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 4:\n",
        "\n",
        "con4_layer = Conv1D(nb_filter,\n",
        "                    5,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con4_layer = Lambda(max_1d, output_shape=(nb_filter,))(con4_layer)\n",
        "\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 5:\n",
        "\n",
        "con5_layer = Conv1D(nb_filter,\n",
        "                    7,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con5_layer = Lambda(max_1d, output_shape=(nb_filter,))(con5_layer)\n",
        "\n",
        "\n",
        "cnn_layer = concatenate([pool_con3_layer, pool_con5_layer,pool_con4_layer ])\n",
        "\n",
        "\n",
        "#LSTM\n",
        "\n",
        "x = Embedding(max_features, embedding_dims, input_length=maxlen)(input_layer)\n",
        "lstm_layer = LSTM(128, return_sequences=True)(x)\n",
        "lstm_layer_2 = LSTM(128, return_sequences=True)(lstm_layer)\n",
        "lstm_layer_3 = LSTM(128)(lstm_layer_2)\n",
        "\n",
        "# cnn_lstm_layer = concatenate([lstm_layer, lstm_layer_2, lstm_layer_3])\n",
        "\n",
        "dense_layer = Dense(hidden_dims*2, activation='sigmoid')(lstm_layer_3)\n",
        "output_layer= Dropout(0.2)(dense_layer)\n",
        "output_layer = Dense(3, trainable=True,activation='softmax')(output_layer)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "adadelta = Adadelta(1.0, rho=0.95, epsilon=1e-06)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=\"adamax\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    *data_train,\n",
        "    epochs=10,\n",
        "    batch_size=10,\n",
        "    validation_data=data_test,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgejJ72AT4mW",
        "outputId": "70769a9b-bab5-4601-ec07-5d209e16c8fa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "510/510 [==============================] - 70s 89ms/step - loss: 1.1101 - accuracy: 0.3861 - val_loss: 1.0100 - val_accuracy: 0.4943\n",
            "Epoch 2/10\n",
            "510/510 [==============================] - 32s 62ms/step - loss: 0.9579 - accuracy: 0.5329 - val_loss: 0.9287 - val_accuracy: 0.5533\n",
            "Epoch 3/10\n",
            "510/510 [==============================] - 28s 56ms/step - loss: 0.8517 - accuracy: 0.6159 - val_loss: 0.8755 - val_accuracy: 0.6038\n",
            "Epoch 4/10\n",
            "510/510 [==============================] - 28s 54ms/step - loss: 0.7264 - accuracy: 0.6967 - val_loss: 0.8415 - val_accuracy: 0.6400\n",
            "Epoch 5/10\n",
            "510/510 [==============================] - 27s 53ms/step - loss: 0.6300 - accuracy: 0.7455 - val_loss: 0.8572 - val_accuracy: 0.6390\n",
            "Epoch 6/10\n",
            "510/510 [==============================] - 27s 53ms/step - loss: 0.5416 - accuracy: 0.7939 - val_loss: 0.8952 - val_accuracy: 0.6286\n",
            "Epoch 7/10\n",
            "510/510 [==============================] - 27s 53ms/step - loss: 0.4955 - accuracy: 0.8192 - val_loss: 0.9365 - val_accuracy: 0.6333\n",
            "Epoch 8/10\n",
            "510/510 [==============================] - 26s 50ms/step - loss: 0.4354 - accuracy: 0.8445 - val_loss: 1.0397 - val_accuracy: 0.6324\n",
            "Epoch 9/10\n",
            "510/510 [==============================] - 27s 53ms/step - loss: 0.3817 - accuracy: 0.8676 - val_loss: 1.0100 - val_accuracy: 0.6362\n",
            "Epoch 10/10\n",
            "510/510 [==============================] - 26s 51ms/step - loss: 0.3350 - accuracy: 0.8873 - val_loss: 1.0804 - val_accuracy: 0.6305\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f88800a7190>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.preprocessing import sequence as sq\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda, concatenate,Input,TimeDistributed,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "max_features = 21540#14300\n",
        "maxlen = 400\n",
        "batch_size = 10\n",
        "embedding_dims = 200\n",
        "nb_filter = 150\n",
        "filter_length = 3\n",
        "hidden_dims = 100\n",
        "nb_epoch = 14\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "input_layer = Input(shape=(maxlen,),dtype='int32', name='main_input')\n",
        "emb_layer = Embedding(max_features,\n",
        "                    embedding_dims,\n",
        "                    input_length=maxlen\n",
        "                    )(input_layer)\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 3:\n",
        "\n",
        "con3_layer = Conv1D(nb_filter,\n",
        "                    3,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con3_layer = Lambda(max_1d, output_shape=(nb_filter,))(con3_layer)\n",
        "\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 4:\n",
        "\n",
        "con4_layer = Conv1D(nb_filter,\n",
        "                    5,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con4_layer = Lambda(max_1d, output_shape=(nb_filter,))(con4_layer)\n",
        "\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 5:\n",
        "\n",
        "con5_layer = Conv1D(nb_filter,\n",
        "                    7,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con5_layer = Lambda(max_1d, output_shape=(nb_filter,))(con5_layer)\n",
        "\n",
        "\n",
        "cnn_layer = concatenate([pool_con3_layer, pool_con5_layer,pool_con4_layer ])\n",
        "\n",
        "\n",
        "#LSTM\n",
        "\n",
        "x = Embedding(max_features, embedding_dims, input_length=maxlen)(input_layer)\n",
        "lstm_layer = LSTM(128)(x)\n",
        "\n",
        "\n",
        "cnn_lstm_layer = concatenate([lstm_layer, lstm_layer])\n",
        "\n",
        "dense_layer = Dense(hidden_dims*2, activation='sigmoid')(cnn_lstm_layer)\n",
        "output_layer= Dropout(0.2)(dense_layer)\n",
        "output_layer = Dense(3, trainable=True,activation='softmax')(output_layer)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "adadelta = Adadelta(1.0, rho=0.95, epsilon=1e-06)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=\"adamax\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    *data_train,\n",
        "    epochs=10,\n",
        "    batch_size=10,\n",
        "    validation_data=data_test,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB39PvhQOIkr",
        "outputId": "3c6ead14-6b78-4a75-b22c-3d673380a1a1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "510/510 [==============================] - 32s 58ms/step - loss: 1.0613 - accuracy: 0.4365 - val_loss: 0.9198 - val_accuracy: 0.5705\n",
            "Epoch 2/10\n",
            "510/510 [==============================] - 15s 29ms/step - loss: 0.8439 - accuracy: 0.6167 - val_loss: 0.7935 - val_accuracy: 0.6486\n",
            "Epoch 3/10\n",
            "510/510 [==============================] - 12s 24ms/step - loss: 0.7098 - accuracy: 0.7057 - val_loss: 0.8242 - val_accuracy: 0.6276\n",
            "Epoch 4/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.6286 - accuracy: 0.7467 - val_loss: 0.7930 - val_accuracy: 0.6705\n",
            "Epoch 5/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.5678 - accuracy: 0.7733 - val_loss: 0.8383 - val_accuracy: 0.6657\n",
            "Epoch 6/10\n",
            "510/510 [==============================] - 11s 21ms/step - loss: 0.5008 - accuracy: 0.8067 - val_loss: 0.8324 - val_accuracy: 0.6667\n",
            "Epoch 7/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.4487 - accuracy: 0.8251 - val_loss: 0.9101 - val_accuracy: 0.6581\n",
            "Epoch 8/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.4067 - accuracy: 0.8480 - val_loss: 0.9463 - val_accuracy: 0.6648\n",
            "Epoch 9/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.3679 - accuracy: 0.8649 - val_loss: 0.9941 - val_accuracy: 0.6705\n",
            "Epoch 10/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.3193 - accuracy: 0.8806 - val_loss: 1.0622 - val_accuracy: 0.6714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f88ce6b6740>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.preprocessing import sequence as sq\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda, concatenate,Input,TimeDistributed,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "max_features = 21540#14300\n",
        "maxlen = 400\n",
        "batch_size = 10\n",
        "embedding_dims = 200\n",
        "nb_filter = 150\n",
        "filter_length = 3\n",
        "hidden_dims = 100\n",
        "nb_epoch = 14\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "input_layer = Input(shape=(maxlen,),dtype='int32', name='main_input')\n",
        "emb_layer = Embedding(max_features,\n",
        "                    embedding_dims,\n",
        "                    input_length=maxlen\n",
        "                    )(input_layer)\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 3:\n",
        "\n",
        "con3_layer = Conv1D(nb_filter,\n",
        "                    3,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con3_layer = Lambda(max_1d, output_shape=(nb_filter,))(con3_layer)\n",
        "\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 4:\n",
        "\n",
        "con4_layer = Conv1D(nb_filter,\n",
        "                    5,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con4_layer = Lambda(max_1d, output_shape=(nb_filter,))(con4_layer)\n",
        "\n",
        "\n",
        "# we add a Convolution1D, which will learn nb_filter\n",
        "# word group filters of size 5:\n",
        "\n",
        "con5_layer = Conv1D(nb_filter,\n",
        "                    7,\n",
        "                    padding='valid',\n",
        "                    activation='relu',)(emb_layer)\n",
        "\n",
        "pool_con5_layer = Lambda(max_1d, output_shape=(nb_filter,))(con5_layer)\n",
        "\n",
        "\n",
        "cnn_layer = concatenate([pool_con3_layer, pool_con5_layer,pool_con4_layer ])\n",
        "\n",
        "\n",
        "#LSTM\n",
        "\n",
        "x = Embedding(max_features, embedding_dims, input_length=maxlen)(input_layer)\n",
        "lstm_layer = LSTM(128)(x)\n",
        "\n",
        "\n",
        "cnn_lstm_layer = concatenate([lstm_layer, lstm_layer])\n",
        "\n",
        "dense_layer = Dense(hidden_dims*2, activation='sigmoid')(cnn_lstm_layer)\n",
        "output_layer= Dropout(0.2)(dense_layer)\n",
        "output_layer = Dense(3, trainable=True,activation='softmax')(output_layer)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "adadelta = Adadelta(1.0, rho=0.95, epsilon=1e-06)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=\"rmsprop\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    *data_train,\n",
        "    epochs=10,\n",
        "    batch_size=10,\n",
        "    validation_data=data_test,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4CEjp9VWJPC",
        "outputId": "af2c2f26-62f8-4174-8c04-9a555bb87df2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "510/510 [==============================] - 27s 48ms/step - loss: 1.0621 - accuracy: 0.4373 - val_loss: 0.9582 - val_accuracy: 0.5571\n",
            "Epoch 2/10\n",
            "510/510 [==============================] - 13s 25ms/step - loss: 0.8142 - accuracy: 0.6559 - val_loss: 0.7925 - val_accuracy: 0.6514\n",
            "Epoch 3/10\n",
            "510/510 [==============================] - 13s 25ms/step - loss: 0.6906 - accuracy: 0.7214 - val_loss: 0.7809 - val_accuracy: 0.6629\n",
            "Epoch 4/10\n",
            "510/510 [==============================] - 11s 22ms/step - loss: 0.6036 - accuracy: 0.7706 - val_loss: 0.7927 - val_accuracy: 0.6762\n",
            "Epoch 5/10\n",
            "510/510 [==============================] - 10s 19ms/step - loss: 0.5294 - accuracy: 0.8043 - val_loss: 0.8102 - val_accuracy: 0.6581\n",
            "Epoch 6/10\n",
            "510/510 [==============================] - 11s 22ms/step - loss: 0.4584 - accuracy: 0.8288 - val_loss: 0.8771 - val_accuracy: 0.6629\n",
            "Epoch 7/10\n",
            "510/510 [==============================] - 12s 23ms/step - loss: 0.4052 - accuracy: 0.8510 - val_loss: 0.9102 - val_accuracy: 0.6638\n",
            "Epoch 8/10\n",
            "510/510 [==============================] - 12s 24ms/step - loss: 0.3439 - accuracy: 0.8737 - val_loss: 1.0228 - val_accuracy: 0.6543\n",
            "Epoch 9/10\n",
            "510/510 [==============================] - 11s 22ms/step - loss: 0.2926 - accuracy: 0.8949 - val_loss: 1.1052 - val_accuracy: 0.6600\n",
            "Epoch 10/10\n",
            "510/510 [==============================] - 11s 21ms/step - loss: 0.2364 - accuracy: 0.9186 - val_loss: 1.2677 - val_accuracy: 0.6429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f88cd1c5750>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PhoBERT"
      ],
      "metadata": {
        "id": "YTmFqVtIZd7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxKYuA13XRTQ",
        "outputId": "953eedfb-aa55-43cb-8ad3-6d7cae65fc37"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "da4c85e3fd044a23aea8050a6b5f73a6",
            "a0478f08e93d473cbb01982e754ce697",
            "6274c46c3bb94d7994d98c979f8de987",
            "8163317d4cd0422f90816e45770a0e34",
            "5988c3f7d3ba41379579b652916c765f",
            "9ac46ed4f9244a79a7aef457514f3a04",
            "f7d3ab9ae5d14e3385c4ccd630a5ef00",
            "ada5b2571333461f8b69e018873af7f8",
            "def8a19579a4414ba613f042d68f6b36",
            "d166d1fda42341ec841be79acef5a901",
            "270ebe2a76ec40b9a42c3c99c57f2e0d",
            "897be82b2d274a1c96c9575e36cdc923",
            "1adefcee9a2f43b5b5bd18cb0bdce543",
            "9da1deddf9b64b5b8fb0b6306ff9725a",
            "a1a2198d6f59412ca4ed5e6cdf12c198",
            "de71b5f040ce48f9ad676722a54d6ac0",
            "27360e065a58450f93f4ab431245f69e",
            "8f06d66ef58742b4aefb6166c527093f",
            "9d4b93fded444352860dffb009bf68d3",
            "6ab67fdef5204cf4b5f2344a94f7796e",
            "e5879f38b6d345d5a2f5e8e55b08820b",
            "003664cd03ce4bdfa7dff22fbcc21f08",
            "1ba0c34c1bb1490da1e27c4f13d74c16",
            "3e28bd5ff09c406f9560bd586af5174c",
            "ca4debb4216e49169801245f83c7ff8a",
            "bbae2e88ffb04949b455b84758149b9f",
            "1e99660664e1456497bc5ef0755e76c2",
            "876989b2f7f84f55a4d5a5aa50fd81af",
            "d8fb617a7eea4f03bca72e85156f2412",
            "ae7eda2ab0074b4dba3a9a8ea8323e9a",
            "29636ee9dd3d456b9f62d1d4dea1daf5",
            "20801dcbc4b54cc2874d733c00b00654",
            "af937dbde4744bd89237d2023d50cb03",
            "387e11b94cb344598848ecf1e5b8fbb5",
            "e281f98667df404eb348f5b9963c8ecd",
            "eb18e47c675e4a36b4c252799072fdca",
            "531b38ec83074a9bab73ae3727b861b9",
            "737595e03ca3400f8723c6c5f4503e4d",
            "623e530e0a66495186bb22d918cb1c77",
            "c8c0e937c98f4451b0e8eef84361e67f",
            "45c82e14cb3345149d0ef87927713428",
            "721c735d40874f73bb183875e1953fce",
            "22bd04b7faa74460811212306ee554ae",
            "08325274087844278b2333951ab7882b"
          ]
        },
        "id": "fiuziFfJZYv9",
        "outputId": "3feb3516-2b92-4069-f8d8-9cb67809f8af"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da4c85e3fd044a23aea8050a6b5f73a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "897be82b2d274a1c96c9575e36cdc923"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ba0c34c1bb1490da1e27c4f13d74c16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "387e11b94cb344598848ecf1e5b8fbb5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lion_pytorch import Lion\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "def eval_fn(data_loader, model):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            ids = d[\"ids\"]\n",
        "            mask = d[\"mask\"]\n",
        "            targets = d[\"targets\"]\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(ids=ids, mask=mask)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "        fin_outputs = np.array(fin_outputs) >= 0.5\n",
        "\n",
        "        acc = np.average(fin_targets == fin_outputs)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "OQUx1d2IZZOQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv(\"vlsp_sentiment_train.csv\", sep='\\t')\n",
        "data_train.columns =['Class', 'Data']\n",
        "data_train = data_train.sample(frac=1)\n",
        "\n",
        "data_test = pd.read_csv(\"vlsp_sentiment_test.csv\", sep='\\t')\n",
        "data_test.columns =['Class', 'Data']"
      ],
      "metadata": {
        "id": "ABZiyGsiZcZb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
      ],
      "metadata": {
        "id": "cZt_sboOZh4s"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zvFGWUZZjKf",
        "outputId": "093e3b84-1005-46d3-c6d9-0776cc0bc4b4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textaugment import EDA, AEDA\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "eda = EDA()\n",
        "aeda = AEDA()\n",
        "\n",
        "def tokenize(text):\n",
        "    return tokenizer(\n",
        "        text, padding='max_length', truncation=True, max_length=MAX_LEN,\n",
        "        return_tensors='np'\n",
        "    )\n",
        "\n",
        "def preprocess(text, label, aug=True):\n",
        "\n",
        "    if aug:\n",
        "        text = eda.random_deletion(text, p=0.2)\n",
        "        # text = eda.random_swap(text)\n",
        "        text = eda.random_insertion(text)\n",
        "\n",
        "        # text = aeda.punct_insertion(text)\n",
        "\n",
        "    if label == -1:\n",
        "        label = [1, 0, 0]\n",
        "    elif label == 0:\n",
        "        label = [0, 1, 0]\n",
        "    else:\n",
        "        label = [0, 0, 1]\n",
        "\n",
        "    return text, label"
      ],
      "metadata": {
        "id": "gXtZ-eP6ZkgZ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tweet_Dataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len, aug):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.aug = aug\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        tweet = str(self.data['Data'][index])\n",
        "\n",
        "        targets = self.data['Class'][index]\n",
        "\n",
        "        text, label = preprocess(tweet, targets, aug=self.aug)\n",
        "\n",
        "        inputs = tokenize(text)\n",
        "\n",
        "        ids = inputs['input_ids'][0]\n",
        "        mask = inputs['attention_mask'][0]\n",
        "\n",
        "        return {\n",
        "            'ids': ids,\n",
        "            'mask': mask,\n",
        "            'targets': torch.tensor(label, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "Ae8IudNWZlro"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = tweet_Dataset(data_train, tokenizer, MAX_LEN, aug=True)\n",
        "validation_set = tweet_Dataset(data_test, tokenizer, MAX_LEN, aug=False)\n",
        "\n",
        "train_params = {'batch_size': BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "valid_params = {'batch_size': BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "train_dl = DataLoader(training_set, **train_params)\n",
        "valid_dl = DataLoader(validation_set, **valid_params)"
      ],
      "metadata": {
        "id": "yoiiU9dqZnHj"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.distill_bert = transformers.AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
        "        self.drop = torch.nn.Dropout(0.3)\n",
        "        self.out = torch.nn.Linear(768, 3)\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        distilbert_output = self.distill_bert(ids, mask)\n",
        "        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n",
        "        pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
        "        output_1 = self.drop(pooled_output)\n",
        "        output = self.out(output_1)\n",
        "        return output\n",
        "\n",
        "model = DistillBERTClass()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8f31kNTZob6",
        "outputId": "513902ba-1209-4040-dd4b-7ed657c4618d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistillBERTClass(\n",
              "  (distill_bert): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(num_epochs, model, loss_fn, opt, train_dl, valid_dl):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for _, data in (pbar := tqdm(enumerate(train_dl, 0), unit=\"batch\", total=len(train_dl), position=0, leave=True)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask).squeeze()\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            pbar.set_description(f\"Loss: {loss.item():.4f} \")\n",
        "\n",
        "        valid_acc = eval_fn(valid_dl, model)\n",
        "        print('Epoch [{}/{}], Train Loss: {:.4f} and Validation acc {:.4f}'.format(epoch+1, num_epochs, loss.item(),valid_acc))"
      ],
      "metadata": {
        "id": "hcv7lcffZp2R"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Lion(model.parameters(), lr=4e-6, weight_decay=3e-2)\n",
        "\n",
        "fit(3, model, loss_fn, optimizer, train_dl, valid_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4ZuRlTKZsal",
        "outputId": "7d6d8464-5a31-4db8-be41-12868743f6f7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.6166 : 100%|██████████| 160/160 [01:50<00:00,  1.45batch/s]\n",
            "100%|██████████| 33/33 [00:07<00:00,  4.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Train Loss: 0.6166 and Validation acc 0.6854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.3660 : 100%|██████████| 160/160 [01:49<00:00,  1.47batch/s]\n",
            "100%|██████████| 33/33 [00:06<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/3], Train Loss: 0.3660 and Validation acc 0.8032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.3683 : 100%|██████████| 160/160 [01:49<00:00,  1.47batch/s]\n",
            "100%|██████████| 33/33 [00:06<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/3], Train Loss: 0.3683 and Validation acc 0.8156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCt2ZPwqZ2va"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}